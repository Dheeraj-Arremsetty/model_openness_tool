framework:
  name: 'Model Openness Framework'
  version: '1.0'
  date: '2024-12-15'
release:
  name: Bilingual-gpt-neox-4b
  version: 3.8B
  date: '2024-11-15'
  license: {  }
  type: language
  architecture: 'transformer decoder'
  origin: GPT-NeoX
  producer: Rinna
  contact: ''
  huggingface: 'https://huggingface.co/rinna/bilingual-gpt-neox-4b'
  components:
    -
      name: 'Model architecture'
      description: "Well commented code for the model's architecture"
      license: 'MIT license'
    -
      name: 'Model parameters (Final)'
      description: 'Trained model parameters, weights and biases'
      license: MIT
    -
      name: Datasets
      description: 'Training, validation and testing datasets used for the model'
      license: 'mc4, cc100, wikipedia, EleutherAI/pile, togethercomputer/RedPajama-Data-1T'
    -
      name: 'Model card'
      description: 'Model details including performance metrics, intended use, and limitations'
      license: unlicensed
    -
      name: 'Data card'
      description: 'Documentation for datasets including source, characteristics, and preprocessing details'
      license: unlicensed
    -
      name: 'Technical report'
      description: 'Technical report detailing capabilities and usage instructions for the model'
      license: unlicensed
    -
      name: 'Research paper'
      description: 'Research paper detailing the development and capabilities of the model'
      license: unlicensed
